# Neural-Network-AND-Gate-with-Gradient-Descent-in-C-
This project implements a simple neural network in C++ to simulate an AND gate using a one-neuron architecture. The network is trained using the gradient descent algorithm, with a sigmoid activation function. The model learns to predict the correct output for the AND truth table over multiple epochs. The results are saved to a file and also displayed in the terminal. The code is structured for easy understanding and further experimentation in neural network basics.

Features:

Implements gradient descent for weight optimization.
Uses a sigmoid activation function for smooth output between 0 and 1.
Trains on the AND logic gate dataset.
Displays and logs training progress, including cost function, weights, and predictions.
Usage: Run the C++ program to train the neural network. Results will be saved in output_results.txt and displayed in the terminal.
